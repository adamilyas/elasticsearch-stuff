{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from geoip2 import database\n",
    "reader = database.Reader('./geoip/GeoLite2-City_20190611/GeoLite2-City.mmdb')\n",
    "\n",
    "HOSTNAME = \"100.88.37.43\"\n",
    "PORT = 9200\n",
    "ADDR = f\"http://{HOSTNAME}:{PORT}\"\n",
    "\n",
    "headers = {'Content-type': 'application/json'}\n",
    "\n",
    "def create_url(index_name, end_point=\"\", i=\"\"):\n",
    "    return f\"{ADDR}/{index_name}/{end_point}/{i}\"\n",
    "\n",
    "def bulk_send_dataframe(df, index):\n",
    "    \"\"\"\n",
    "    index: elastic search index that you want to send to\n",
    "    Example: \n",
    "    index=\"netflow\":\n",
    "    or index=\"features\"\n",
    "    Returns\n",
    "        json message\n",
    "    \"\"\"\n",
    "    action = { \"index\" : { \"_index\" : index}}\n",
    "    action = json.dumps(action)\n",
    "    # convert dataframe to list of dict\n",
    "    to_send = [row.to_dict() for i, row in df.iterrows()]\n",
    "    data_to_post = f\"{action}\\n\" + f\"\\n{action}\\n\".join(json.dumps(d) for d in to_send)+ \"\\n\"\n",
    "    r = requests.post(url=f\"{ADDR}/_bulk?pretty\", data=data_to_post, headers=headers)\n",
    "    return r.json()\n",
    "    \n",
    "def geo_helper(ip):\n",
    "    \"\"\"\n",
    "    Extract the following from ip (String)\n",
    "    - Latitude\n",
    "    - Longitude\n",
    "    - Country\n",
    "    Returns\n",
    "        [\"{Latitude},{Longitude}\", Country] or [None, None]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = reader.city(ip)\n",
    "        lat = response.location.latitude\n",
    "        lon = response.location.longitude\n",
    "        geostring = f\"{round(lat,2)},{round(lon,2)}\"\n",
    "        country = response.country.names[\"en\"]\n",
    "        return [geostring, country]\n",
    "    except:\n",
    "        return [None, None]\n",
    "    \n",
    "def add_geoinformation(df, dest_col, src_col=None):\n",
    "    \"\"\"\n",
    "    https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html\n",
    "    \n",
    "    Read from df[dest_col] (and df[src_col] if given src_col)\n",
    "    for each ip in each col:\n",
    "    Apply geo_helper on each ip to create 2 new columns: \n",
    "    df[\"dest_location\"] and df[\"dest_country\"] (and src_location and src_country if given src_col)\n",
    "    Returns:\n",
    "        Dataframe with additional columns\n",
    "    \"\"\"\n",
    "    dest_addr = df[dest_col]\n",
    "    if src_col is not None:\n",
    "        src_addr = df[src_col]\n",
    "        addr = pd.concat([src_addr, dest_addr])\n",
    "    else:\n",
    "        addr = dest_addr\n",
    "        \n",
    "    geo_map = {ip: geo_helper(ip) for ip in addr.unique()}\n",
    "    \n",
    "    if src_col is not None:\n",
    "        src_result = list(zip(*src_addr.map(geo_map)))\n",
    "        df[\"src_location\"], df[\"src_country\"] = src_result\n",
    "    \n",
    "    dest_result = list(zip(*dest_addr.map(geo_map)))\n",
    "    df[\"dest_location\"], df[\"dest_country\"] = dest_result\n",
    "        \n",
    "    return df\n",
    "\n",
    "def add_geoinformation_and_send_dataframe(df, index):\n",
    "    if index==\"netflow\":\n",
    "        src_col=\"IPV4_SRC_ADDR\"\n",
    "    if index==\"features\":\n",
    "        src_col=None\n",
    "    df = add_geoinformation(df, dest_col='IPV4_DST_ADDR', src_col=src_col)\n",
    "    response_message = bulk_send_dataframe(df, index)\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_success(df, response_result):\n",
    "    N, d = df.shape\n",
    "    n_success = len(response_result[\"items\"])\n",
    "    print(f\"Sent {n_success} out of {N} successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'features'}\n",
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'netflow'}\n"
     ]
    }
   ],
   "source": [
    "requests.delete(create_url(\"features\"))\n",
    "requests.delete(create_url(\"netflow\"))\n",
    "\n",
    "# define the mapping\n",
    "features_schema = { \n",
    "        \"IPV4_DST_ADDR\": {\"type\": \"ip\"},\n",
    "        \"dest_location\": { \"type\" : \"geo_point\" }, \n",
    "        \"record_time\": {\n",
    "            \"type\": \"date\",\n",
    "            \"format\": \"yyyy-MM-dd HH:mm:ss\"\n",
    "                       }\n",
    "}\n",
    "\n",
    "netflow_schema = { \n",
    "        \"Attack\":      { \"type\": \"integer\" },\n",
    "        \"IPV4_SRC_ADDR\": {\"type\": \"ip\"},\n",
    "        \"IPV4_DST_ADDR\": {\"type\": \"ip\"},\n",
    "        \"EXPORTER_IPV4_ADDRESS\": {\"type\": \"ip\"},\n",
    "        \"src_location\": { \"type\" : \"geo_point\" },\n",
    "        \"dest_location\": { \"type\" : \"geo_point\" }, \n",
    "        \"record_time\": {\n",
    "            \"type\": \"date\",\n",
    "            \"format\": \"yyyy-MM-dd HH:mm:ss\"\n",
    "                       }\n",
    "}\n",
    "\n",
    "url = create_url(\"features\")\n",
    "r = requests.put(url=url, \n",
    "                 json={\"mappings\": {\"properties\": features_schema}},\n",
    "                 headers=headers)\n",
    "print(r.json())\n",
    "\n",
    "url = create_url(\"netflow\")\n",
    "r = requests.put(url=url, \n",
    "                 json={\"mappings\": {\"properties\": netflow_schema}},\n",
    "                 headers=headers)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflow = pd.read_csv(\"data.csv\")\n",
    "features = pd.read_csv(\"20-min-features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflow\n",
    "# unique_time = netflow.record_time.unique()\n",
    "# unique_time = pd.to_datetime(unique_time)\n",
    "# unique_time\n",
    "# new_times = (unique_time + timedelta(minutes=20))\n",
    "# time_map = {unique_time[i].strftime(\"%Y-%m-%d %H:%M:00\"): new_times[i].strftime(\"%Y-%m-%d %H:%M:00\") \\\n",
    "#             for i in range(len(new_times))}\n",
    "# time_map\n",
    "# netflow[\"record_time\"] = netflow.record_time.map(time_map)\n",
    "# features[\"record_time\"] = features.record_time.map(time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-12-01 00:00:00', '2018-12-01 00:01:00',\n",
       "       '2018-12-01 00:02:00', '2018-12-01 00:03:00',\n",
       "       '2018-12-01 00:04:00', '2018-12-01 00:05:00',\n",
       "       '2018-12-01 00:06:00', '2018-12-01 00:07:00',\n",
       "       '2018-12-01 00:08:00', '2018-12-01 00:09:00',\n",
       "       '2018-12-01 00:10:00', '2018-12-01 00:11:00',\n",
       "       '2018-12-01 00:12:00', '2018-12-01 00:13:00',\n",
       "       '2018-12-01 00:14:00', '2018-12-01 00:15:00',\n",
       "       '2018-12-01 00:16:00', '2018-12-01 00:17:00',\n",
       "       '2018-12-01 00:18:00', '2018-12-01 00:19:00'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "# current_time = datetime.now()\n",
    "# current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "unique_time = features.record_time.unique()\n",
    "unique_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-07-17 04:17:17'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_time_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/adam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-17 04:19:16\n",
      "Sent 22 out of 22 successful\n",
      "Time taken: 0.705718994140625\n",
      "2019-07-17 04:19:46\n",
      "Sent 22 out of 22 successful\n",
      "Time taken: 0.6540226936340332\n",
      "2019-07-17 04:20:17\n",
      "Sent 23 out of 23 successful\n",
      "Time taken: 0.7681765556335449\n",
      "2019-07-17 04:20:48\n",
      "Sent 23 out of 23 successful\n",
      "Time taken: 0.7407703399658203\n",
      "2019-07-17 04:21:19\n",
      "Sent 21 out of 21 successful\n",
      "Time taken: 0.6633322238922119\n",
      "2019-07-17 04:21:50\n",
      "Sent 23 out of 23 successful\n",
      "Time taken: 0.7512097358703613\n",
      "2019-07-17 04:22:20\n",
      "Sent 20 out of 20 successful\n",
      "Time taken: 0.654097318649292\n",
      "2019-07-17 04:22:51\n",
      "Sent 19 out of 19 successful\n",
      "Time taken: 0.6461508274078369\n",
      "2019-07-17 04:23:22\n",
      "Sent 21 out of 21 successful\n",
      "Time taken: 0.6468310356140137\n",
      "2019-07-17 04:23:53\n",
      "Sent 22 out of 22 successful\n",
      "Time taken: 0.6633543968200684\n",
      "2019-07-17 04:24:23\n",
      "Sent 21 out of 21 successful\n",
      "Time taken: 0.6991755962371826\n",
      "2019-07-17 04:24:54\n",
      "Sent 21 out of 21 successful\n",
      "Time taken: 0.6846144199371338\n",
      "2019-07-17 04:25:25\n",
      "Sent 21 out of 21 successful\n",
      "Time taken: 0.6554968357086182\n",
      "2019-07-17 04:25:56\n",
      "Sent 20 out of 20 successful\n",
      "Time taken: 0.6525070667266846\n",
      "2019-07-17 04:26:27\n",
      "Sent 20 out of 20 successful\n",
      "Time taken: 0.6677906513214111\n",
      "2019-07-17 04:26:57\n",
      "Sent 24 out of 24 successful\n",
      "Time taken: 0.7552170753479004\n",
      "2019-07-17 04:27:28\n",
      "Sent 20 out of 20 successful\n",
      "Time taken: 0.6754446029663086\n",
      "2019-07-17 04:27:59\n",
      "Sent 21 out of 21 successful\n",
      "Time taken: 0.6644704341888428\n",
      "2019-07-17 04:28:30\n",
      "Sent 22 out of 22 successful\n",
      "Time taken: 0.6515014171600342\n",
      "2019-07-17 04:29:00\n",
      "Sent 21 out of 21 successful\n",
      "Time taken: 0.6648061275482178\n"
     ]
    }
   ],
   "source": [
    "for r_time in unique_time:\n",
    "#     print(r_time)\n",
    "    df = features[features[\"record_time\"] == r_time]\n",
    "    df = add_geoinformation(df, dest_col='IPV4_DST_ADDR')\n",
    "    current_time_string = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(current_time_string)\n",
    "    df[\"record_time\"] = current_time_string\n",
    "    start = time.time()\n",
    "    response_result = bulk_send_dataframe(df, 'features')\n",
    "    test_success(df, response_result)\n",
    "    print(f\"Time taken: {time.time() - start}\")\n",
    "    \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_time = netflow.record_time.unique()\n",
    "\n",
    "for r_time in unique_time:\n",
    "    if r_time in unique_time[:4]:\n",
    "        continue\n",
    "    print(r_time)\n",
    "    df = netflow[netflow[\"record_time\"] == r_time]\n",
    "    df = add_geoinformation(df, dest_col='IPV4_DST_ADDR', src_col= 'IPV4_SRC_ADDR')\n",
    "    start = time.time()\n",
    "    response_result = bulk_send_dataframe(df, 'netflow')\n",
    "    test_success(df, response_result)\n",
    "    print(f\"Time taken: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table csv? dataframe\n",
    "# everyone minute\n",
    "# send to dashboard\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_time in unique_time:\n",
    "    print(r_time)\n",
    "    df = netflow[netflow[\"record_time\"] == r_time]\n",
    "    df = add_geoinformation(df, dest_col='IPV4_DST_ADDR', src_col= 'IPV4_SRC_ADDR')\n",
    "    \n",
    "    start = time.time()\n",
    "    response_result = bulk_send_dataframe(df, 'netflow')\n",
    "    test_success(df, response_result)\n",
    "    print(f\"Time taken: {time.time() - start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
